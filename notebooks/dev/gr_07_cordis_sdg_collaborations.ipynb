{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORDIS SDG Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we perform preliminary analysis to answer the hypothesis: \n",
    "\n",
    "_There is a positive link between the R&I funding and national performance on the SDG index._\n",
    "\n",
    "We investigate the relationship between research specialisation in the H2020 programme and the 2019 SDG Index scores for goals 3, 6, 7 and 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy\n",
    "\n",
    "from sdg_mapping.cordis import load_cordis_projects, load_cordis_project_sdgs\n",
    "from sdg_mapping.cordis.cordis_utils import FRAMEWORK_PROGRAMMES\n",
    "from sdg_mapping.utils.sdg_utils import sdg_hex_color_codes, sdg_names\n",
    "from sdg_mapping.sdg_index.sdg_index_utils import load_sdg_index\n",
    "\n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = os.path.join(project_dir, 'reports', 'analysis_cordis_sdg_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_h2020_df = load_cordis_projects('h2020').set_index('rcn')\n",
    "project_sdgs_h2020_df = load_cordis_project_sdgs('h2020', 'label').set_index('rcn')\n",
    "\n",
    "sdg_index_df = load_sdg_index(2019, index_type='report')\n",
    "\n",
    "project_sdgs_h2020_df[0] = 0\n",
    "project_sdgs_h2020_df[0][project_sdgs_h2020_df.sum(axis=1) == 0] = 1\n",
    "\n",
    "sdg_keys = [3, 6, 7, 11]\n",
    "sdg_index_score_keys = ['goal_{}_score'.format(g) for g in sdg_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Country Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_coordinator_eu_codes(x):\n",
    "    d = {'EL': 'GR', 'UK': 'GB'}\n",
    "    if x in d:\n",
    "        return d[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def fillna_list(x):\n",
    "    if type(x) == list:\n",
    "        return x\n",
    "    elif pd.isnull(x):\n",
    "        return []\n",
    "    \n",
    "def replace_participant_eu_codes(x):\n",
    "    d = {'EL': 'GR', 'UK': 'GB'}\n",
    "    new = []\n",
    "    for s in x:\n",
    "        if s in d:\n",
    "            new.append(iso2_to_iso3_map[d[s]])\n",
    "        elif s == 'XK': # Code for Kosovo, which is not in the SDG Index data\n",
    "            continue\n",
    "        else:\n",
    "            new.append(iso2_to_iso3_map[s])\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_json(f'{data_path}/raw/countries/countries_restcountries_api.json')\n",
    "iso2_to_iso3_map = {iso2: iso3 for iso2, iso3 in zip(country_df['alpha2Code'], country_df['alpha3Code'])}\n",
    "\n",
    "project_h2020_df['coordinator_country'] = (project_h2020_df['coordinator_country']\n",
    "                                           .apply(lambda x: replace_coordinator_eu_codes(x))\n",
    "                                           .map(iso2_to_iso3_map))\n",
    "project_h2020_df['participant_countries'] = project_h2020_df['participant_countries'].apply(lambda x: fillna_list(x))\n",
    "\n",
    "project_h2020_df['participant_countries'] = (project_h2020_df['participant_countries']\n",
    "                                             .apply(lambda x: replace_participant_eu_codes(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country Location Quotients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_countries(projects):\n",
    "    \n",
    "    null_participants = pd.isnull(projects['participant_countries']).sum() > 0\n",
    "    if null_participants:\n",
    "        projects['participant_countries'] = (projects['participant_countries']\n",
    "                                             .apply(lambda p: fillna_list(p)))\n",
    "    all_countries = []\n",
    "    for c, p in zip(projects['coordinator_country'], projects['participant_countries']):\n",
    "        if pd.isnull(c):\n",
    "            all_countries.append(p)\n",
    "        else:\n",
    "            all_countries.append([c] + p)\n",
    "    return all_countries\n",
    "\n",
    "def create_quotient(X, binary=False):\n",
    "    \"\"\"Calculate the location quotient\n",
    "\n",
    "    Divides the share of activity in a location by the share of activity in the UK total\n",
    "\n",
    "    Args:\n",
    "        X (pandas.DataFrame): DataFrame where rows are locations, columns are sectors \n",
    "            and values are activity in a given sector at a location.\n",
    "        binary (bool, optional): If True, discretise the data with a cut-off value of 1\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "    \"\"\"\n",
    "    Xm = X.values\n",
    "    X = pd.DataFrame((Xm/Xm.sum(1)[:, np.newaxis])/(Xm.sum(0)/Xm.sum()),\n",
    "            index=X.index, columns=X.columns)\n",
    "\n",
    "    return (X > 1) if binary else X\n",
    "\n",
    "def create_cordis_country_lq(projects, values, country_col, binary=False):\n",
    "    '''create_cordis_country_lq\n",
    "    Calculates the country based location quotient for CORDIS project participants\n",
    "    or coordinators.\n",
    "    \n",
    "    Args:\n",
    "        projects (pd.DataFrame): CORDIS projects dataframe. Should have\n",
    "            project rcn as the index.\n",
    "        country_col (str): Name of `projects` column with countries of interest. \n",
    "        values (pd.DataFrame): A dataframe of values to calculate location quotient. \n",
    "            Should have project rcn as the index.\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): CORDIS country based location quotients\n",
    "    '''\n",
    "    countries = projects[country_col].explode()\n",
    "    country_values = pd.merge(countries, values, left_index=True, right_index=True, how='inner')\n",
    "    country_values = country_values.groupby(country_col).sum()\n",
    "    return create_quotient(country_values, binary=binary)\n",
    "\n",
    "def create_cordis_country_sum(projects, values, country_col):\n",
    "    '''create_cordis_country_lq\n",
    "    Calculates the country based location quotient for CORDIS project participants\n",
    "    or coordinators.\n",
    "    \n",
    "    Args:\n",
    "        projects (pd.DataFrame): CORDIS projects dataframe. Should have\n",
    "            project rcn as the index.\n",
    "        country_col (str): Name of `projects` column with countries of interest. \n",
    "        values (pd.DataFrame): A dataframe of values to calculate location quotient. \n",
    "            Should have project rcn as the index.\n",
    "        binary: \n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): CORDIS country based location quotients\n",
    "    '''\n",
    "    countries = projects[country_col].explode()\n",
    "    country_values = pd.merge(countries, values, left_index=True, right_index=True, how='inner')\n",
    "    return country_values.groupby(country_col).sum()\n",
    "\n",
    "def normalise(df, norm=0):\n",
    "    '''normalise\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A quantitative dataframe.\n",
    "        norm (int): The axis along which to normalise. 0 normalises along columns and \n",
    "            1 normalises along rows.\n",
    "    '''\n",
    "    if norm == 0:\n",
    "        df = df.divide(df.sum(axis=0), axis=1)\n",
    "    elif norm == 1:\n",
    "        df = df.divide(df.sum(axis=1), axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_h2020_df['all_countries'] = generate_all_countries(project_h2020_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Collaboration Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooccurrence_edges(groups):\n",
    "    \"\"\"cooccurrence_edges\n",
    "    \n",
    "    \"\"\"\n",
    "    edges = chain(*[[tuple(sorted(c)) for c in (combinations(d, 2))] for d in groups])\n",
    "    edge_counts = Counter(edges)\n",
    "    return edge_counts\n",
    "\n",
    "def cooccurence_nodes(groups):\n",
    "    \"\"\"cooccurrence_nodes\n",
    "    \"\"\"\n",
    "    nodes = list(chain(*groups))\n",
    "    node_counts = Counter(nodes)\n",
    "    return node_counts\n",
    "\n",
    "def country_collaboration_network(project_df, sdg_df, country_col, goal ):\n",
    "    \"\"\"country_collaboration_network\n",
    "    \"\"\"\n",
    "    ids = sdg_df[sdg_df[goal] == 1].index.values\n",
    "    co_nodes = cooccurence_nodes(project_df[country_col].reindex(ids))\n",
    "    co_edges = cooccurrence_edges(project_df[country_col].reindex(ids))\n",
    "    \n",
    "    g = nx.Graph()\n",
    "\n",
    "    for node, weight in co_nodes.items():\n",
    "        g.add_node(node, weight=weight)\n",
    "\n",
    "    for edge, weight in co_edges.items():\n",
    "        g.add_edge(edge[0], edge[1], weight=weight)\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    g = country_collaboration_network(project_h2020_df, project_sdgs_h2020_df, 'all_countries', goal)\n",
    "    giant = max(nx.connected_component_subgraphs(g), key=len)\n",
    "    nx.draw(giant, node_color=sdg_hex_color_codes()[goal], edge_color='gray', alpha=0.7, ax=ax)\n",
    "    ax.set_title(sdg_names()[goal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.diversity.alpha import shannon, simpson\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "dums = mlb.fit_transform(project_h2020_df['all_countries'])\n",
    "dums = pd.DataFrame(dums, columns=mlb.classes_, index=project_h2020_df.index)\n",
    "sums = dums.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Number of Collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):    \n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    sums_goal = sums.reindex(ids)\n",
    "    sums_goal = sums_goal[sums_goal > 1]\n",
    "    sums_goal.plot.hist(bins=range(1, 31), ax=ax, color=sdg_hex_color_codes()[goal])\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "    ax.set_xlabel('Collaborators per Project')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_collaborators_by_sdg_hist.png', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*projects with more than one participant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborator Diversity over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dums = pd.get_dummies(orgs_h2020_df['org_type']).groupby('rcn').sum()\n",
    "simps = dums.apply(simpson, axis=1)\n",
    "shans = dums.apply(shannon, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    sums = dums.sum(axis=1)\n",
    "    simp = simps[sums > 1].reindex(ids).dropna()\n",
    "    ids = simp.index.values\n",
    "    \n",
    "    years = project_h2020_df['start_date'].dt.year.loc[ids]\n",
    "    \n",
    "    div = pd.DataFrame({'simp': simp, 'year': years})\n",
    "    div = div[(div['year'] > 2014) & (div['year'] < 2020)]\n",
    "    \n",
    "    sns.stripplot(data=div, y='simp', x='year', ax=ax, color=sdg_hex_color_codes()[goal], alpha=0.3)\n",
    "    div.groupby('year')['simp'].mean().reset_index(drop=True).plot(color=sdg_hex_color_codes()[goal], \n",
    "                                                                   linewidth=2, ax=ax)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Simpson Index')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{project_dir}/reports/analysis_cordis_sdg_collaborations/org_simpson_vs_year_by_sdg_stripplot.png', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    sums = dums.sum(axis=1)\n",
    "    shan = shans[sums > 1].reindex(ids).dropna()\n",
    "    ids = shan.index.values\n",
    "    \n",
    "    years = project_h2020_df['start_date'].dt.year.loc[ids]\n",
    "    \n",
    "    div = pd.DataFrame({'shan': shan, 'year': years})\n",
    "    div = div[(div['year'] > 2014) & (div['year'] < 2020)]\n",
    "    \n",
    "    sns.stripplot(data=div, y='shan', x='year', ax=ax, color=sdg_hex_color_codes()[goal], alpha=0.3)\n",
    "    div.groupby('year')['shan'].mean().reset_index(drop=True).plot(color=sdg_hex_color_codes()[goal], \n",
    "                                                                   linewidth=2, ax=ax)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Shannon Index')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{project_dir}/reports/analysis_cordis_sdg_collaborations/org_shannon_vs_year_by_sdg_stripplot.png', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharey=True)\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    sums = dums.sum(axis=1)\n",
    "    \n",
    "    totals = dums[sums > 1]\n",
    "    totals = ((totals > 0).sum(axis=1) > 1).astype(int)\n",
    "    years = project_h2020_df['start_date'].dt.year.loc[ids]\n",
    "    div = pd.DataFrame({'totals': totals, 'year': years})\n",
    "    \n",
    "    div = div[(div['year'] > 2014) & (div['year'] < 2020)]\n",
    "    counts = div.groupby('year').mean()\n",
    "    counts.plot(ax=ax, color=sdg_hex_color_codes()[goal], linewidth=2, legend=None, marker='o')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('% of Multi Org Type Projects')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{project_dir}/reports/analysis_cordis_sdg_collaborations/frac_multi_org_projects_vs_year_by_sdg_line.png', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of SDG Share by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_sdg_counts = create_cordis_country_sum(project_h2020_df, project_sdgs_h2020_df, 'all_countries')\n",
    "country_sdg_counts = country_sdg_counts[country_sdg_counts.sum(axis=1) >= 10]\n",
    "\n",
    "sdg_share_country = normalise(country_sdg_counts, norm=1) * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "data = sdg_share_country[sdg_keys].melt()\n",
    "palette = itemgetter(*sdg_keys)(sdg_hex_color_codes())\n",
    "sns.boxplot(x='variable', y='value', data=data, ax=ax, palette=palette)\n",
    "ax.set_xlabel('Goal')\n",
    "ax.set_ylabel('Country Project Share (%)')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{project_dir}/reports/analysis_cordis_sdg_collaborations/country_project_share_by_sdg_boxplot.png', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see each SDG as the share of a country's projects. For exmaple, for Goal 3 we can see that at one country has over 40% of it's projects related to the goal.\n",
    "\n",
    "This shows that although some goals are much more prevalent than others, there are countries which specialise much more than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP()\n",
    "umap_vecs = umap.fit_transform(dums[dums.sum(axis=1) > 1])\n",
    "umap_df = pd.DataFrame(umap_vecs, columns=['x', 'y'], index=dums[dums.sum(axis=1) > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_df['all_countries'] = project_h2020_df['all_countries'].loc[dums[dums.sum(axis=1) > 1].index.values].str.join(', ')\n",
    "\n",
    "alt.Chart(umap_df.sample(5000)).mark_point().encode(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    tooltip='all_countries'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get country sdg project count by date\n",
    "- does the number of collaborations drive the future specialisation of projects by that country?\n",
    "\n",
    "- Does the SDG Index performance of a country go up after its first collaboration with another country on an SDG?\n",
    "- Is SDG Index performance impacted by participation in a project?\n",
    "- What is the difference in SDG profiles between private and public sector?\n",
    "- Does an increase in SDG research correspond to an increase or decrease in SDG Index performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the difference in SDG index performance between the first year of a collaboration and the year after.\n",
    "2. Figure out if the difference is more or less than the average increase that year? Or if the percentage increases in performance are better or worse than those who do not participate. Or does the rate of improvement change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisation Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to know whether different SDGs have different collaboration structures between organisations. Are there more distinct or centralised communities for one SDG? Can we describe those communities by the distribution of their disciplinarity specialisations (of the organisations). e.g does an SDG have more distinct communities that also have stronger disciplinary specialisations or is there a highly interdisciplinary overlap?\n",
    "\n",
    "Are there collaboration clusters?\n",
    "\n",
    "Change in network structure over time:\n",
    "\n",
    "- Motif analysis?\n",
    "- Change in centrality\n",
    "- Distribution of centrality?\n",
    "- Community detection?\n",
    "\n",
    "How does this network composition relate to SDG Index performance?\n",
    "\n",
    "What are the differences between a country's performance on the SDG Index based on it's collaboration (% of projects done in collaboration vs change in SDG Index score). Does collaboration lead a greater than expected increase in share of projects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_parsed_dir = f'{data_path}/processed/cordis/h2020/h2020_orgs_xml'\n",
    "\n",
    "dfs = []\n",
    "for file in os.listdir(xml_parsed_dir):\n",
    "    dfs.append(pd.read_json(os.path.join(xml_parsed_dir, file)))\n",
    "    \n",
    "orgs_h2020_df = pd.concat(dfs, sort=True)\n",
    "\n",
    "del dfs\n",
    "\n",
    "orgs_h2020_df['iso3_code'] = orgs_h2020_df['iso2_code'].map(iso2_to_iso3_map)\n",
    "orgs_h2020_df = orgs_h2020_df.set_index('rcn').drop('metadata.xml')\n",
    "orgs_h2020_df['org_type'] = orgs_h2020_df['org_type'].str.replace('/', '')\n",
    "project_orgs = orgs_h2020_df.groupby('rcn')['legal_name'].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Participants by Organisation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_project_ids(sdg_df, goal):\n",
    "    return sdg_df[sdg_df[goal] == 1].index.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs_h2020_df.index = orgs_h2020_df.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sdg_project_ids(project_sdgs_h2020_df, 3)\n",
    "proj_ids = orgs_h2020_df.index.intersection(ids).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for ax, goal in zip(axs, sdg_keys):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "#     org_type_counts = orgs_h2020_df.loc[orgs_h2020_df.index.intersection(ids)]['org_type'].value_counts()\n",
    "    org_type_counts = orgs_h2020_df.loc[ids]['org_type'].value_counts()\n",
    "    org_type_counts.sort_index().plot.bar(color=sdg_hex_color_codes()[goal], ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Org Type')\n",
    "    ax.set_ylabel('Involvement Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_org_type_by_sdg_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for goal in sdg_keys:\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "#     org_type_counts = orgs_h2020_df.loc[orgs_h2020_df.index.intersection(ids)]['org_type'].value_counts()\n",
    "    org_type_counts = orgs_h2020_df.loc[ids]['org_type'].value_counts()\n",
    "    org_type_counts = (org_type_counts / org_type_counts.sum()).sort_index()\n",
    "    df[goal] = org_type_counts * 100\n",
    "    \n",
    "df = df.loc[df.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "sns.heatmap(df.T, ax=ax, cmap='viridis', annot=True)\n",
    "ax.set_xlabel('Org Type')\n",
    "ax.set_ylabel('Goal')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/frac_org_type_by_sdg_heatmap.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for goal in sdg_keys:\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "#     org_type_counts = orgs_h2020_df.loc[orgs_h2020_df.index.intersection(ids)]['org_type'].value_counts()\n",
    "    org_type_counts = orgs_h2020_df.loc[ids]['org_type'].value_counts()\n",
    "    org_type_counts = (org_type_counts / org_type_counts.sum()).sort_index()\n",
    "    df[goal] = org_type_counts\n",
    "    \n",
    "order = df.sum(axis=1).sort_values(ascending=False).index\n",
    "df = df.loc[order]\n",
    "all_org_frac = orgs['org_type'].value_counts() / orgs['org_type'].value_counts().sum()\n",
    "df_spec = df.divide(all_org_frac, axis=0).loc[order]\n",
    "\n",
    "sns.heatmap(df.T * 100, ax=ax[0], cmap='viridis', annot=True,\n",
    "            cbar_kws={'label': 'Share of Organisations'})\n",
    "sns.heatmap(df_spec.T, ax=ax[1], cmap='bwr_r', annot=True, \n",
    "            cbar_kws={'label': 'Representation'}, center=1\n",
    "           )\n",
    "ax[0].set_xlabel('Org Type')\n",
    "ax[1].set_ylabel('Goal')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     f'{project_dir}/reports/analysis_cordis_sdg_collaborations/frac_org_type_by_sdg_heatmap.png', \n",
    "#     dpi=300\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of instances of different organisation types participating in a project shows that some SDGs are much more likely to be carried out by certain types of organisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Project Coordinators by Organisation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for ax, goal in zip(axs, sdg_keys):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "    orgs = orgs_h2020_df[orgs_h2020_df['type'] == 'coordinator']\n",
    "    org_type_counts = orgs.loc[ids]['org_type'].value_counts()\n",
    "    org_type_counts.sort_index().plot.bar(color=sdg_hex_color_codes()[goal], ax=ax)\n",
    "    ax.set_xlabel('Org Type')\n",
    "    ax.set_ylabel('Coordinator Frequency')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_coord_vs_org_type_by_sdg_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for goal in sdg_keys:\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "    orgs = orgs_h2020_df[orgs_h2020_df['type'] == 'coordinator']\n",
    "#     org_type_counts = orgs_h2020_df.loc[orgs_h2020_df.index.intersection(ids)]['org_type'].value_counts()\n",
    "    org_type_counts = orgs.loc[ids]['org_type'].value_counts()\n",
    "    org_type_counts = (org_type_counts / org_type_counts.sum()).sort_index()\n",
    "    df[goal] = org_type_counts\n",
    "\n",
    "# order = df.sum(axis=1).sort_values(ascending=False).index\n",
    "df = df.loc[order]\n",
    "all_org_frac = orgs['org_type'].value_counts() / orgs['org_type'].value_counts().sum()\n",
    "df_spec = df.divide(all_org_frac, axis=0).loc[order]\n",
    "\n",
    "sns.heatmap(df.T * 100, ax=ax[0], cmap='viridis', annot=True,\n",
    "            cbar_kws={'label': 'Share of Coordinators'})\n",
    "sns.heatmap(df_spec.T, ax=ax[1], cmap='bwr_r', annot=True, \n",
    "            cbar_kws={'label': 'Representation'}, center=1\n",
    "           )\n",
    "ax[0].set_xlabel('Org Type')\n",
    "ax[1].set_ylabel('Goal')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     f'{project_dir}/reports/analysis_cordis_sdg_collaborations/frac_org_type_by_sdg_heatmap.png', \n",
    "#     dpi=300\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_all = orgs_h2020_df[orgs_h2020_df['type'] == 'coordinator']\n",
    "coord_counts_all = coords_all['org_type'].value_counts() / coords_all.shape[0] * 100\n",
    "coord_counts_all = coord_counts_all.sort_index()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharey=True)\n",
    "\n",
    "for ax, goal in zip(axs, sdg_keys):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "    orgs = orgs_h2020_df[orgs_h2020_df['type'] == 'coordinator']\n",
    "    org_type_counts = orgs.loc[ids]['org_type'].value_counts() / len(ids) * 100\n",
    "    org_type_counts.sort_index().plot.bar(color=sdg_hex_color_codes()[goal], ax=ax)\n",
    "    ax.scatter(coord_counts_all.index, coord_counts_all.values, color='C0', zorder=5, marker='_', s=100)\n",
    "    ax.set_xlabel('Org Type')\n",
    "    ax.set_ylabel('Coordinator Frequency')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/frac_coord_vs_org_type_by_sdg_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same ordering broadly hold true across SDGs if we only look at the project coordinators. Although we see that the number of public and other organisations decrease dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for ax, goal in zip(axs, sdg_keys):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "    orgs = orgs_h2020_df[orgs_h2020_df['type'] == 'coordinator']\n",
    "    orgs = orgs.drop_duplicates(subset='legal_name')\n",
    "    org_type_counts = orgs.loc[orgs.index.intersection(ids)]['org_type'].value_counts()\n",
    "    org_type_counts.plot.bar(color=sdg_hex_color_codes()[goal], ax=ax)\n",
    "    ax.set_xlabel('Org Type')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_unique_orgs_vs_org_type_by_sdg_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look instead at the number of organisations involved in each SDG, we see a very different picture. There are generally very large numbers of private organisations in comparison to all other types. This makes sense perhaps because private organisations are typically smaller and focus on one area or project, while organisations such as universities and foundations will be involved in very large portfolios of work and may hold multiple simultaneous projects on a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_org_type_counts = orgs_h2020_df.drop_duplicates('legal_name')['org_type'].value_counts()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharey=True)\n",
    "\n",
    "for ax, goal in zip(axs, sdg_keys):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "    orgs = orgs_h2020_df.loc[ids]\n",
    "    org_type_counts = orgs.drop_duplicates(subset='legal_name')['org_type'].value_counts()\n",
    "    org_type_counts = org_type_counts / unique_org_type_counts * 100\n",
    "    org_type_counts.plot.bar(color=sdg_hex_color_codes()[goal], ax=ax)\n",
    "    ax.set_xlabel('Org Type')\n",
    "    ax.set_ylabel('% of Orgs')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/frac_unique_orgs_vs_org_type_by_sdg_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the actual percentage of all organisations in each type that have been involved in SDG related work? As we can see, significant proportions of higher education establishments tend to be involved in projects across all the Goals. Each goal has its own profile however; private companies are highly represented for SDG 7, while public institutions are the most highly represented in SDG 11, which might be expected due to the nature of these Goals' topics.\n",
    "\n",
    "So what about the distribution of projects among these organisations? For each organisation type, do we have many organisations involved in many projects or a small number of organisations hoarding all of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), \n",
    "#                         sharex=True\n",
    "                        sharey=True\n",
    "                       )\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "\n",
    "    a = (orgs_h2020_df\n",
    "         .loc[ids]\n",
    "         .groupby(['org_type', 'legal_name'])['type']\n",
    "         .count()\n",
    "         .unstack(level=0)\n",
    "        )\n",
    "    x = a / a.sum() * 100\n",
    "\n",
    "    for c in x.columns:\n",
    "        X = x[c].dropna()\n",
    "\n",
    "        xs = np.sort(X)\n",
    "        n = np.arange(1, len(X)+1) / np.float(len(X))\n",
    "        ax.step(xs, n, label=c) \n",
    "\n",
    "    ax.set_xlim(-0.1, 4)\n",
    "    ax.set_ylabel('Cumulative Frequency (Norm)')\n",
    "    ax.set_xlabel('Proportion of Projects (%)')\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/project_share_vs_org_by_org_type_by_sdg_cumulhist.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), \n",
    "#                         sharex=True\n",
    "#                         sharey=True\n",
    "                       )\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "\n",
    "    a = (orgs_h2020_df\n",
    "         .loc[ids]\n",
    "         .groupby(['org_type', 'legal_name'])['type']\n",
    "         .count()\n",
    "         .unstack(level=0)\n",
    "        )\n",
    "#     x = a / a.sum() * 100\n",
    "    x = a\n",
    "\n",
    "    for c in x.columns:\n",
    "        X = x[c].dropna()\n",
    "\n",
    "        xs = np.sort(X)\n",
    "        n = np.arange(1, len(X)+1) / np.float(len(X))\n",
    "        ax.step(xs, n, label=c) \n",
    "\n",
    "#     ax.set_xlim(-0.1, 4)\n",
    "    ax.set_ylabel('Cumulative Frequency (Norm)')\n",
    "    ax.set_xlabel('N Projects')\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_projects_vs_org_by_org_type_by_sdg_cumulhist.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the organisational share of projects within each organisation type and for each SDG. This gives us an idea as to how concentrated projects are within organisations. The further a curve reaches to the top left of the graph, the more distributed projects are (more organisations have a smaller share of projects), wheres a collapsing curve means that there are more organisations that have accumulated a larger share of projects.\n",
    "\n",
    "For each SDG, the trend and level of concentration is different. For example, projects in Goals 3 and 7 tend to be much more distributed than projects for Goal 6. We can see that private organisations tend to have a much more distributed share of projects. For the other types, the ordering of highest to lowest distributed appears to depend on the goal. For example in SDG 3, public institutions have a highly concentrated project distribution. For sustainable cities and communities however, they are the second most distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = (orgs_h2020_df\n",
    "         .groupby(['org_type', 'legal_name'])['type']\n",
    "         .count()\n",
    "         .unstack(level=0)\n",
    "        )\n",
    "\n",
    "\n",
    "x = a / a.sum() * 100\n",
    "\n",
    "for c in x.columns:\n",
    "    X = x[c].dropna()\n",
    "\n",
    "    xs = np.sort(X)\n",
    "    n = np.arange(1, len(X)+1) / np.float(len(X))\n",
    "    ax.step(xs, n, label=c) \n",
    "\n",
    "ax.set_xlim(-0.1, 1.5)\n",
    "ax.set_ylabel('Cumulative Frequency (Normalised)')\n",
    "ax.set_xlabel('Proportion of Projects (%)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/project_share_vs_org_by_org_type_cumulhist.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = (orgs_h2020_df\n",
    "         .groupby(['org_type', 'legal_name'])['type']\n",
    "         .count()\n",
    "         .unstack(level=0)\n",
    "        )\n",
    "\n",
    "\n",
    "# x = a / a.sum() * 100\n",
    "x = a\n",
    "\n",
    "for c in x.columns:\n",
    "    X = x[c].dropna()\n",
    "\n",
    "    xs = np.sort(X)\n",
    "    n = np.arange(1, len(X)+1) / np.float(len(X))\n",
    "    ax.step(xs, n, label=c) \n",
    "\n",
    "# ax.set_xlim(-0.1, 1.5)\n",
    "ax.set_ylabel('Cumulative Frequency (Normalised)')\n",
    "ax.set_xlabel('Number of Projects')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_projects_vs_org_by_org_type_cumulhist.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference this is the distribution across all H2020 projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharey=True) \n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "\n",
    "    x = (orgs_h2020_df\n",
    "         .loc[ids]\n",
    "         .groupby(['org_type', 'legal_name'])['type']\n",
    "         .count()\n",
    "         .unstack(level=0)\n",
    "        )\n",
    "    x = x / x.sum() * 100    \n",
    "    x = x.melt()\n",
    "\n",
    "    sns.boxplot(data=x, x='org_type', y='value', showfliers=False, ax=ax, color=sdg_hex_color_codes()[goal])\n",
    "\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/project_share_vs_org_by_org_type_by_sdg_box.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharey=True) \n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "\n",
    "    x = (orgs_h2020_df\n",
    "         .loc[ids]\n",
    "         .groupby(['org_type', 'legal_name'])['type']\n",
    "         .count()\n",
    "         .unstack(level=0)\n",
    "        ) \n",
    "#     x = x / x.sum() * 100    \n",
    "    x = x.melt()\n",
    "\n",
    "    sns.boxplot(data=x, x='org_type', y='value', showfliers=False, ax=ax, color=sdg_hex_color_codes()[goal])\n",
    "\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/n_projects_vs_org_by_org_type_by_sdg_box.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These boxplots are another way of seeing the same project concentration levels as the cumulative histograms above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the levels of collaboration between different types of organisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisation Type Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_counts = orgs_h2020_df.groupby('rcn')['org_type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = project_sdgs_h2020_df[sdg_keys].unstack().reset_index(level=0).rename(columns={'level_0': 'goal', 0: 'is_goal'})\n",
    "s = s[s['is_goal'] == 1]\n",
    "s = s.drop('is_goal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def sorted_set(x):\n",
    "    return sorted(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combos = pd.get_dummies(orgs_h2020_df.groupby('rcn')['org_type'].apply(sorted_set).astype(str))\n",
    "cols = [', '.join(sorted(ast.literal_eval(c))) for c in df_combos.columns]\n",
    "df_combos.columns = cols\n",
    "cols.sort(key=lambda s: len(s))\n",
    "df_combos = df_combos[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_shares = df_combos.sum() / df_combos.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, figsize=(8, 8), sharex=True)\n",
    "\n",
    "combos = {}\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "\n",
    "    a = (df_combos\n",
    "         .loc[ids]\n",
    "        )\n",
    "    a = pd.Series(a.sum() / a.shape[0] * 100)\n",
    "    combos[goal] = a\n",
    "    x = a / combo_shares\n",
    "    x.plot.bar(ax=ax, color=['C0' if n >= 1 else 'C3' for n in x])\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "    ax.axhline(1, c='gray', linestyle='--')\n",
    "    ax.set_xlabel('Organisational Combination')\n",
    "    ax.set_ylabel('Relative Proportion')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/org_type_combo_representation_by_sdg_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, figsize=(8, 16))\n",
    "\n",
    "combos = {}\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "\n",
    "    a = (df_combos\n",
    "         .loc[ids]\n",
    "        )\n",
    "    a = pd.Series(a.sum() / a.shape[0] * 100)\n",
    "    combos[goal] = a\n",
    "    x = a / combo_shares\n",
    "    x.sort_values().plot.bar(ax=ax, color=['C0' if n >= 1 else 'C3' for n in x.sort_values()])\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "    ax.axhline(1, c='gray', linestyle='--')\n",
    "    ax.set_xlabel('Organisational Combination')\n",
    "    ax.set_ylabel('Relative Proportion')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/org_type_combo_representation_by_sdg_sorted_bar.png', \n",
    "    dpi=300\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the levels of the different forms of organisational composition for each SDG compared to the levels across all projects. This reveals whether there are particular organisational compositions that are preferred for particular goals.\n",
    "\n",
    "For Good Health and Well-being we can see that there are more projects that involve collaborations between public bodies and research organisations than average, as well as those with public, research and private organisations. Almost every other type of combination is at or below the average level.\n",
    "\n",
    "On the other hand, Goals 6 and 11 have an over-representation of projects that involve a wider spectrum of organisation types.\n",
    "\n",
    "Goal 7 has a significant representation of combinations that include private and 'other' type organisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do countries with high performance have usual or unusual combinations of organisation types for a particular SDG?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Organisation Type Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collabs = orgs_h2020_df.groupby('rcn')['org_type'].apply(list)\n",
    "collab_counts_all = pd.Series(Counter(list(chain(*[combinations(sorted(c), 2) for c in collabs]))))\n",
    "collab_frac_all = collab_counts_all / collab_counts_all.sum()\n",
    "collab_frac_all = collab_frac_all.unstack().T / collab_frac_all.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_counts = {}\n",
    "\n",
    "for goal in sdg_keys:\n",
    "    ids = sdg_project_ids(project_sdgs_h2020_df, goal)\n",
    "    collabs_g = collabs.loc[ids]\n",
    "    collab_counts[goal] = pd.Series(Counter(list(chain(*[combinations(sorted(c), 2) for c in collabs_g]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 6), sharex=True, sharey=True)\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "\n",
    "    x = (collab_counts[goal].unstack().T / collab_counts[goal].sum().sum()) / collab_frac_all\n",
    "    sns.heatmap(x, cmap='coolwarm_r', ax=ax, center=1, square=True)\n",
    "    ax.set_title(sdg_names()[goal])\n",
    "    ax.set_xlabel('Org Type')\n",
    "    ax.set_ylabel('Org Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    f'{project_dir}/reports/analysis_cordis_sdg_collaborations/org_type_pairwise_combo_representation_by_sdg_heatmap.png', \n",
    "    dpi=600\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at pairwise collaborations only, we see some of the underlying patterns. Good Health and Well-being has a significant over-representation of higher education institutions collaborating with other types of institutions, and themselves, as well as public bodies and research institutions.\n",
    "\n",
    "**This is in effect a function of frequency - how do we address this? Using a model or by normalising to account for frequency?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about combinations of countries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there goals which are similar in terms of function or system but but have totally organisational compositions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sense of the concentration of projects Of the projects that organisations of a particular type are involved in, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_years = (project_h2020_df['end_date'] - project_h2020_df['start_date']).dt.days / 365.25\n",
    "\n",
    "for goal in sdg_keys:\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    y = duration_years.loc[ids]\n",
    "    print(f'Mean duration for Goal {goal}: {np.round(y.mean(), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy\n",
    "import warnings\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.corpora import Dictionary\n",
    "from graph_tool.all import Graph\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from rhodonite.cooccurrence import cooccurrence_graph\n",
    "from rhodonite.cooccurrence.normalise import association_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_orgs_h2020 = project_sdgs_h2020_df.merge(orgs_h2020_df, left_index=True, right_index=True, how='left')\n",
    "project_orgs = orgs_h2020_df.groupby(orgs_h2020_df.index)['legal_name'].apply(list)\n",
    "\n",
    "org_sdg_counts = sdg_orgs_h2020.groupby('legal_name')[sdg_keys + [0]].sum()\n",
    "org_sdg_specialisation = create_quotient(org_sdg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_h2020_df = orgs_h2020_df[orgs_h2020_df['type'] == 'coordinator']\n",
    "part_h2020_df = orgs_h2020_df[orgs_h2020_df['type'] != 'coordinator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_pairs_h2020_df = pd.merge(coords_h2020_df['legal_name'], part_h2020_df['legal_name'], \n",
    "                                 left_index=True, right_index=True, how='right', suffixes=('_c', '_p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_pairs_h2020_df = (collab_pairs_h2020_df\n",
    "                       .merge(org_sdg_specialisation, left_on='legal_name_c', right_index=True, how='left')\n",
    "                        )\n",
    "collab_pairs_h2020_df = (collab_pairs_h2020_df\n",
    "                       .merge(org_sdg_specialisation, left_on='legal_name_p', right_index=True, how='left', \n",
    "                              suffixes=('_c', '_p'))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharex=True) \n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    collab_pairs_goal = collab_pairs_h2020_df.loc[collab_pairs_h2020_df.index.intersection(ids)]\n",
    "    diff = collab_pairs_goal[f'{goal}_c'] - collab_pairs_goal[f'{goal}_p']\n",
    "    diff = diff / diff.std()\n",
    "    diff.plot.hist(ax=ax, color=sdg_hex_color_codes()[goal], bins=25, density='normed')\n",
    "    ax.axvline(diff.mean(), color='gray', linestyle='--')\n",
    "    print(goal, diff.mean())\n",
    "    ax.set_xlabel('Specialisation Difference (Norm)')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general we see that the specialisation of a project coordinator is lower than that of the other participants on a project. We see differences between the goals too, with Goal 3 having the smallest relative difference between coordinators and participants.\n",
    "\n",
    "One issue here is that specialisation tends to be higher for organisations that take on fewer projects and that those with fewer projects are less likely to be coordinators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_pairs_h2020_df = (collab_pairs_h2020_df\n",
    "                       .merge(org_sdg_counts, left_on='legal_name_c', right_index=True, how='left')\n",
    "                        )\n",
    "collab_pairs_h2020_df = (collab_pairs_h2020_df\n",
    "                       .merge(org_sdg_counts, left_on='legal_name_p', right_index=True, how='left', \n",
    "                              suffixes=('_count_c', '_count_p'))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), \n",
    "#                         sharex=True\n",
    "                       ) \n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs):\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    collab_pairs_goal = collab_pairs_h2020_df.loc[collab_pairs_h2020_df.index.intersection(ids)]\n",
    "    diff = collab_pairs_goal[f'{goal}_count_c'] - collab_pairs_goal[f'{goal}_count_p']\n",
    "#     diff = diff / diff.std()\n",
    "    diff.plot.hist(ax=ax, color=sdg_hex_color_codes()[goal], bins=25)\n",
    "    ax.axvline(diff.mean(), color='gray', linestyle='--')\n",
    "    print(goal, diff.mean())\n",
    "    ax.set_xlabel('Project Count Difference')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that normally the number of projects a coordinator has engaged in is larger than the number of projects other participants have engaged in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_orgs_collab = project_orgs[project_orgs.apply(lambda x: len(x)) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_graphs = {}\n",
    "for goal in sdg_keys:\n",
    "\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "\n",
    "    # project_hes = project_orgs.dropna()\n",
    "    sdg_orgs = project_orgs_collab.loc[project_orgs_collab.index.intersection(ids)]\n",
    "    dictionary = Dictionary(sdg_orgs)\n",
    "    org_ids = [dictionary.doc2idx(d) for d in sdg_orgs]\n",
    "\n",
    "    g_co, o, co = cooccurrence_graph(org_ids)\n",
    "    g_co.vp['o'] = o\n",
    "    g_co.ep['co'] = co\n",
    "    collab_graphs[goal] = g_co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.stats import vertex_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharex=True)\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    n, bins = vertex_hist(collab_graphs[goal], deg='out')\n",
    "    ax.scatter(bins[1:], n, color=sdg_hex_color_codes()[goal], alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.9, 1000)\n",
    "    ax.set_xlabel('Node Degree')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharex=True)\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    n, bins = vertex_hist(collab_graphs[goal], deg='out')\n",
    "    bins = bins / collab_graphs[goal].num_vertices()\n",
    "    ax.scatter(bins[1:], n, color=sdg_hex_color_codes()[goal], alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.9, 1000)\n",
    "    ax.set_xlabel('Node Degree')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3), sharex=True)\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    n, bins = vertex_hist(collab_graphs[goal], deg='out')\n",
    "    ax.step(bins[1:], np.cumsum(n) / np.cumsum(n).max(), color=sdg_hex_color_codes()[goal], alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.centrality import betweenness, eigenvector, pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    collab_graphs[goal].vp['betweeness'], collab_graphs[goal].ep['betweeness'] = betweenness(\n",
    "        collab_graphs[goal],\n",
    "#         weight=collab_graphs[goal].ep['co']\n",
    "                          )\n",
    "    ax.hist(collab_graphs[goal].vp['betweeness'].a, bins=25, color=sdg_hex_color_codes()[goal])\n",
    "#     ax.set_xscale('log')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    _, collab_graphs[goal].vp['eigenvector'] = eigenvector(\n",
    "        collab_graphs[goal],\n",
    "#         weight=collab_graphs[goal].ep['co']\n",
    "                          )\n",
    "    ax.hist(collab_graphs[goal].vp['eigenvector'].a, bins=25, color=sdg_hex_color_codes()[goal])\n",
    "#     ax.set_xscale('log')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    collab_graphs[goal].vp['pagerank'] = pagerank(\n",
    "        collab_graphs[goal],\n",
    "#         weight=collab_graphs[goal].ep['co']\n",
    "                          )\n",
    "    ax.hist(collab_graphs[goal].vp['pagerank'].a, bins=25, color=sdg_hex_color_codes()[goal])\n",
    "#     ax.set_xscale('log')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.clustering import local_clustering, global_clustering\n",
    "from graph_tool.draw import graph_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    collab_graphs[goal].vp['cluster_coeff'] = local_clustering(\n",
    "        collab_graphs[goal],\n",
    "#         weight=collab_graphs[goal].ep['co']\n",
    "                          )\n",
    "    ax.hist(collab_graphs[goal].vp['cluster_coeff'].a, bins=25, color=sdg_hex_color_codes()[goal])\n",
    "#     ax.set_xscale('log')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    collab_graphs[goal].vp['od'] = collab_graphs[goal].new_vertex_property('float')\n",
    "    x = (collab_graphs[goal]\n",
    "                                   .get_out_degrees(vs=list(collab_graphs[goal].vertices()))\n",
    "                                   )\n",
    "    x = x / (collab_graphs[goal].num_vertices() - 1)\n",
    "    collab_graphs[goal].vp['od'].a = x\n",
    "    ax.hist(collab_graphs[goal].vp['od'].a, bins=50, color=sdg_hex_color_codes()[goal])\n",
    "#     ax.set_xscale('log')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhodonite.utils.tabular import vertices_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    vertex_df = vertices_to_dataframe(collab_graphs[goal]).set_index('v')\n",
    "    vertex_df = vertex_df.rename(columns={'o': 'frequency', 'od': 'out degree'})\n",
    "    sns.heatmap(vertex_df.corr(), cmap='viridis', ax=ax, vmin=-0.6)\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = {}\n",
    "\n",
    "for goal in sdg_keys:\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "\n",
    "    # project_hes = project_orgs.dropna()\n",
    "    sdg_orgs = project_orgs_collab.loc[project_orgs_collab.index.intersection(ids)]\n",
    "    dictionaries[goal] = Dictionary(sdg_orgs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3), ncols=2)\n",
    "\n",
    "for goal in sdg_keys:\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    sdg_orgs = project_orgs_collab.loc[project_orgs_collab.index.intersection(ids)]\n",
    "    dictionary = dictionaries[goal]\n",
    "    mms = MinMaxScaler()\n",
    "    vertex_df = vertices_to_dataframe(collab_graphs[goal]).set_index('v')\n",
    "    vertex_df['legal_name'] = vertex_df.index.map(dictionary)\n",
    "    org_types = orgs_h2020_df[['org_type', 'legal_name']].drop_duplicates()\n",
    "    vertex_df = vertex_df.merge(org_types.reset_index(), left_on='legal_name', right_on='legal_name', how='left')\n",
    "    vertex_df[['betweeness', 'cluster_coeff']] = mms.fit_transform(vertex_df[['betweeness', 'cluster_coeff']])\n",
    "    v = vertex_df.groupby('org_type')[['betweeness', 'cluster_coeff']].mean().sort_index()\n",
    "    v_err = vertex_df.groupby('org_type')[['betweeness', 'cluster_coeff']].std().sort_index()\n",
    "    ax[0].scatter(v.index, v['betweeness'], color=sdg_hex_color_codes()[goal])\n",
    "    ax[0].set_ylabel('Betweeness')\n",
    "    ax[1].scatter(v.index, v['cluster_coeff'], color=sdg_hex_color_codes()[goal])\n",
    "    ax[1].set_ylabel('Clustering Coefficient')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GraphView for the nodes in each European country and calculat the clustering coefficient for that graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool import GraphView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eu_country_codes():\n",
    "    country_df = pd.read_json(f'{data_path}/raw/countries/countries_restcountries_api.json')\n",
    "    europe = []\n",
    "    for code, c in zip(country_df['alpha2Code'], country_df['regionalBlocs']):\n",
    "        for x in c:\n",
    "            if x['acronym'] == 'EU':\n",
    "                europe.append(code)\n",
    "    \n",
    "    # Britain called 'UK' in CORDIS\n",
    "    europe = sorted(['UK' if e == 'GB' else e for e in europe])\n",
    "    return europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe = generate_eu_country_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coeffs = defaultdict(list)\n",
    "clustering_err = defaultdict(list)\n",
    "\n",
    "for goal in sdg_keys:\n",
    "    for country in europe:\n",
    "        country_orgs = orgs_h2020_df[orgs_h2020_df['nuts_code'] == country]['legal_name'].drop_duplicates()\n",
    "        country_org_vertices = [dictionaries[goal].token2id[k] for k in country_orgs if k in dictionaries[goal].token2id]\n",
    "        \n",
    "        is_country = collab_graphs[goal].new_vp('bool')\n",
    "        for org in country_org_vertices:\n",
    "            is_country[org] = True\n",
    "        gv = GraphView(collab_graphs[3], vfilt=is_country)\n",
    "        coeff = global_clustering(gv)\n",
    "        clustering_coeffs[goal].append(coeff[0])\n",
    "        clustering_err[goal].append(coeff[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_orgs = {}\n",
    "\n",
    "for goal in sdg_keys:\n",
    "    ids = project_sdgs_h2020_df[project_sdgs_h2020_df[goal] == 1].index.values\n",
    "    countries = orgs_h2020_df[['nuts_code', 'legal_name']].loc[ids]\n",
    "    countries = countries.drop_duplicates('legal_name')\n",
    "    n_orgs[goal] = countries['nuts_code'].value_counts().reindex(europe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_orgs = pd.DataFrame(n_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame(data=clustering_coeffs, index=europe)\n",
    "cluster_err_df = pd.DataFrame(data=clustering_err, index=europe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(15, 3))\n",
    "for goal, ax in zip(sdg_keys, axs.ravel()):\n",
    "    ax.errorbar(x=n_orgs[goal], y=cluster_df[goal], yerr=cluster_err_df[goal], \n",
    "                color=sdg_hex_color_codes()[goal], linestyle=\"None\", marker='o',\n",
    "               alpha=0.7)\n",
    "    ax.set_ylabel('Clustering Coefficient')\n",
    "    ax.set_xlabel('N Orgs (Nodes)')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
